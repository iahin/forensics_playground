{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b63edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from karateclub import DeepWalk\n",
    "from karateclub.dataset import GraphSetReader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c239f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getembedding(graph_list):\n",
    "    scaler = StandardScaler()\n",
    "    dim = 16\n",
    "    embedlist = []\n",
    "    newlistt = []\n",
    "\n",
    "    for x in graph_list:\n",
    "        model = DeepWalk(dimensions=dim)\n",
    "        model.fit(x)\n",
    "        x_embed = model.get_embedding()\n",
    "        x_embed = scaler.fit_transform(x_embed)\n",
    "        x_embed = torch.from_numpy(x_embed)\n",
    "        embedlist.append(x_embed)\n",
    "    seq_len = [len(x) for x in graph_list]\n",
    "    max_len = max(seq_len)\n",
    "    for x in embedlist:\n",
    "        x = F.pad(x, (0, 0, 0 ,max_len - x.shape[0]), \"constant\", 0)\n",
    "        temp = x.reshape([1, dim, max_len])\n",
    "        newlistt.append(temp)\n",
    "    return newlistt\n",
    "\n",
    "def chunkwise(t, size=2):\n",
    "    it = iter(t)\n",
    "    newzipped = zip(*[it]*size)\n",
    "    newlist = [list(x) for x in newzipped]\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a81bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = GraphSetReader(\"reddit10k\") #  two types - discussion and non-discussion based ones.\n",
    "graphlist = reader.get_graphs()[:100]\n",
    "targetlist = reader.get_target()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc0717c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = [(x, y) for x, y in zip(graphlist, targetlist) \n",
    "       #if len(x.edges()) > 50 and len(x.edges()) < 80\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5615a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_x = getembedding([x for x, y in bag])\n",
    "embed_y = [y for x,y in bag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa0cc671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train length: 50 \n",
      "x_test length: 50\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embed_x, embed_y, train_size=0.5, test_size=0.5, random_state=42)\n",
    "print(\n",
    "\"x_train length:\", len(X_train),\"\\n\"\n",
    "\"x_test length:\", len(X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad7bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_sampler(sample_split, classpick):\n",
    "    newbag = []\n",
    "    sample = []\n",
    "    loader = []\n",
    "\n",
    "    for c in classpick:\n",
    "        for x,y in sample_split:\n",
    "            if y==c:\n",
    "                newbag.append((x, y))\n",
    "                break\n",
    "\n",
    "    for img1, y1 in newbag:\n",
    "        for img2, y2 in newbag:\n",
    "            if y1 == y2:\n",
    "                sample.append((img1, img2, 1)) # label 0 if pairs are same \n",
    "            if y1 != y2:\n",
    "                sample.append((img1, img2, 0)) # label 1 if pairs are not same\n",
    "    \n",
    "    for img1, img2, y in sample:\n",
    "        dataload = Data(\n",
    "            img1=img1,\n",
    "            img2=img2,\n",
    "            y=y\n",
    "        )\n",
    "        loader.append(dataload)\n",
    "\n",
    "    return newbag, loader\n",
    "\n",
    "def validation_sampler(sample_split, classpick=None):\n",
    "    newbag = []\n",
    "    loader = []\n",
    "\n",
    "    if classpick:\n",
    "    \n",
    "        for c in classpick:\n",
    "            for x,y in sample_split:\n",
    "                if y==c:\n",
    "                    newbag.append((x, y))\n",
    "                    break\n",
    "                    \n",
    "    else:\n",
    "        newbag = sample_split\n",
    "\n",
    "                \n",
    "    for img, y in newbag:\n",
    "        dataload = Data(\n",
    "            img=img,\n",
    "            y=y\n",
    "        )\n",
    "        loader.append(dataload)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d465248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "validationload, trainload = pair_sampler(\n",
    "    zip(X_train, y_train), \n",
    "    [0,0,0,1,1,1,1],\n",
    "    #np.random.binomial(1, 0.4, 5)\n",
    ")\n",
    "train_loader = DataLoader(trainload, batch_size=1, shuffle=False)\n",
    "print(len(trainload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2b2d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "    def forward(self, output1, output2, label):\n",
    "        #euclidean_distance = torch.cdist(output1, output2)\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd2ecd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/delijati/pytorch-siamese/blob/master/net.py\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork,self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            \n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            \n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(3008, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500,500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500, 2)\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):        \n",
    "        x = self.cnn1(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d10ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 197.32015991210938\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 76.34922790527344\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 3892.815185546875\n",
      "\n",
      "Epoch number 0\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 6.991643905639648\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 8.079567909240723\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 2.884491443634033\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 1.0152783393859863\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 1.9365854263305664\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 0.43034735321998596\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 2.426431894302368\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 0.9521488547325134\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 0.12152929604053497\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 2.268883466720581\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 0.05806535482406616\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 0.13305962085723877\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 5\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 5\n",
      " Current loss 0.3104574978351593\n",
      "\n",
      "Epoch number 5\n",
      " Current loss 0.22207364439964294\n",
      "\n",
      "Epoch number 5\n",
      " Current loss 0.4151366055011749\n",
      "\n",
      "Epoch number 5\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 6\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 6\n",
      " Current loss 0.2664037346839905\n",
      "\n",
      "Epoch number 6\n",
      " Current loss 0.489436537027359\n",
      "\n",
      "Epoch number 6\n",
      " Current loss 0.853524386882782\n",
      "\n",
      "Epoch number 6\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 7\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 7\n",
      " Current loss 0.6501002311706543\n",
      "\n",
      "Epoch number 7\n",
      " Current loss 0.6186470985412598\n",
      "\n",
      "Epoch number 7\n",
      " Current loss 0.5131043195724487\n",
      "\n",
      "Epoch number 7\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 8\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 8\n",
      " Current loss 1.240275502204895\n",
      "\n",
      "Epoch number 8\n",
      " Current loss 0.22121725976467133\n",
      "\n",
      "Epoch number 8\n",
      " Current loss 1.008618950843811\n",
      "\n",
      "Epoch number 8\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 9\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 9\n",
      " Current loss 0.21191847324371338\n",
      "\n",
      "Epoch number 9\n",
      " Current loss 0.14257483184337616\n",
      "\n",
      "Epoch number 9\n",
      " Current loss 0.9422521591186523\n",
      "\n",
      "Epoch number 9\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 10\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 10\n",
      " Current loss 0.9312851428985596\n",
      "\n",
      "Epoch number 10\n",
      " Current loss 0.5027397871017456\n",
      "\n",
      "Epoch number 10\n",
      " Current loss 0.9984096884727478\n",
      "\n",
      "Epoch number 10\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 11\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 11\n",
      " Current loss 0.14469613134860992\n",
      "\n",
      "Epoch number 11\n",
      " Current loss 0.10588321834802628\n",
      "\n",
      "Epoch number 11\n",
      " Current loss 0.873458206653595\n",
      "\n",
      "Epoch number 11\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 12\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 12\n",
      " Current loss 0.9174046516418457\n",
      "\n",
      "Epoch number 12\n",
      " Current loss 0.603926420211792\n",
      "\n",
      "Epoch number 12\n",
      " Current loss 0.9851951599121094\n",
      "\n",
      "Epoch number 12\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 13\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 13\n",
      " Current loss 0.807793915271759\n",
      "\n",
      "Epoch number 13\n",
      " Current loss 0.017582600936293602\n",
      "\n",
      "Epoch number 13\n",
      " Current loss 0.3952096700668335\n",
      "\n",
      "Epoch number 13\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 14\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 14\n",
      " Current loss 0.6006453037261963\n",
      "\n",
      "Epoch number 14\n",
      " Current loss 0.07477287203073502\n",
      "\n",
      "Epoch number 14\n",
      " Current loss 0.5099472999572754\n",
      "\n",
      "Epoch number 14\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 15\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 15\n",
      " Current loss 0.33395227789878845\n",
      "\n",
      "Epoch number 15\n",
      " Current loss 0.053942471742630005\n",
      "\n",
      "Epoch number 15\n",
      " Current loss 0.645511269569397\n",
      "\n",
      "Epoch number 15\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 16\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 16\n",
      " Current loss 0.35020244121551514\n",
      "\n",
      "Epoch number 16\n",
      " Current loss 0.07573491334915161\n",
      "\n",
      "Epoch number 16\n",
      " Current loss 0.7271809577941895\n",
      "\n",
      "Epoch number 16\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 17\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 17\n",
      " Current loss 0.23819436132907867\n",
      "\n",
      "Epoch number 17\n",
      " Current loss 0.08212120831012726\n",
      "\n",
      "Epoch number 17\n",
      " Current loss 0.7616207599639893\n",
      "\n",
      "Epoch number 17\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 18\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 18\n",
      " Current loss 0.2475603073835373\n",
      "\n",
      "Epoch number 18\n",
      " Current loss 0.10835843533277512\n",
      "\n",
      "Epoch number 18\n",
      " Current loss 0.7988442778587341\n",
      "\n",
      "Epoch number 18\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 19\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 19\n",
      " Current loss 0.19418475031852722\n",
      "\n",
      "Epoch number 19\n",
      " Current loss 0.12500765919685364\n",
      "\n",
      "Epoch number 19\n",
      " Current loss 0.7969064116477966\n",
      "\n",
      "Epoch number 19\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 20\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 20\n",
      " Current loss 0.18229900300502777\n",
      "\n",
      "Epoch number 20\n",
      " Current loss 0.13477791845798492\n",
      "\n",
      "Epoch number 20\n",
      " Current loss 0.7713596820831299\n",
      "\n",
      "Epoch number 20\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 21\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 21\n",
      " Current loss 0.16054721176624298\n",
      "\n",
      "Epoch number 21\n",
      " Current loss 0.1645563840866089\n",
      "\n",
      "Epoch number 21\n",
      " Current loss 0.8109042048454285\n",
      "\n",
      "Epoch number 21\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 22\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 22\n",
      " Current loss 0.14861147105693817\n",
      "\n",
      "Epoch number 22\n",
      " Current loss 0.16934093832969666\n",
      "\n",
      "Epoch number 22\n",
      " Current loss 0.831795334815979\n",
      "\n",
      "Epoch number 22\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 23\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 23\n",
      " Current loss 0.1588602066040039\n",
      "\n",
      "Epoch number 23\n",
      " Current loss 0.20128193497657776\n",
      "\n",
      "Epoch number 23\n",
      " Current loss 0.748176634311676\n",
      "\n",
      "Epoch number 23\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 24\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 24\n",
      " Current loss 0.1605939269065857\n",
      "\n",
      "Epoch number 24\n",
      " Current loss 0.15904252231121063\n",
      "\n",
      "Epoch number 24\n",
      " Current loss 0.7942383289337158\n",
      "\n",
      "Epoch number 24\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 25\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 25\n",
      " Current loss 0.15358395874500275\n",
      "\n",
      "Epoch number 25\n",
      " Current loss 0.15822690725326538\n",
      "\n",
      "Epoch number 25\n",
      " Current loss 0.8048698306083679\n",
      "\n",
      "Epoch number 25\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 26\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 26\n",
      " Current loss 0.14662733674049377\n",
      "\n",
      "Epoch number 26\n",
      " Current loss 0.20148111879825592\n",
      "\n",
      "Epoch number 26\n",
      " Current loss 0.8932846784591675\n",
      "\n",
      "Epoch number 26\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 27\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 27\n",
      " Current loss 0.1436638981103897\n",
      "\n",
      "Epoch number 27\n",
      " Current loss 0.16617892682552338\n",
      "\n",
      "Epoch number 27\n",
      " Current loss 0.8142312169075012\n",
      "\n",
      "Epoch number 27\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 28\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 28\n",
      " Current loss 0.15768016874790192\n",
      "\n",
      "Epoch number 28\n",
      " Current loss 0.16444644331932068\n",
      "\n",
      "Epoch number 28\n",
      " Current loss 0.7821316719055176\n",
      "\n",
      "Epoch number 28\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 29\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 29\n",
      " Current loss 0.16175736486911774\n",
      "\n",
      "Epoch number 29\n",
      " Current loss 0.1598060131072998\n",
      "\n",
      "Epoch number 29\n",
      " Current loss 0.748281717300415\n",
      "\n",
      "Epoch number 29\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 30\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 30\n",
      " Current loss 0.15921831130981445\n",
      "\n",
      "Epoch number 30\n",
      " Current loss 0.1448962539434433\n",
      "\n",
      "Epoch number 30\n",
      " Current loss 0.694821834564209\n",
      "\n",
      "Epoch number 30\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 31\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 31\n",
      " Current loss 0.16933931410312653\n",
      "\n",
      "Epoch number 31\n",
      " Current loss 0.1742294728755951\n",
      "\n",
      "Epoch number 31\n",
      " Current loss 0.7217642664909363\n",
      "\n",
      "Epoch number 31\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 32\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 32\n",
      " Current loss 0.15555384755134583\n",
      "\n",
      "Epoch number 32\n",
      " Current loss 0.18239866197109222\n",
      "\n",
      "Epoch number 32\n",
      " Current loss 0.7241963744163513\n",
      "\n",
      "Epoch number 32\n",
      " Current loss 3.9999942779541016\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 33\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 33\n",
      " Current loss 0.14430008828639984\n",
      "\n",
      "Epoch number 33\n",
      " Current loss 0.19563239812850952\n",
      "\n",
      "Epoch number 33\n",
      " Current loss 0.7199106812477112\n",
      "\n",
      "Epoch number 33\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 34\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 34\n",
      " Current loss 0.13839678466320038\n",
      "\n",
      "Epoch number 34\n",
      " Current loss 0.21049699187278748\n",
      "\n",
      "Epoch number 34\n",
      " Current loss 0.7284717559814453\n",
      "\n",
      "Epoch number 34\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 35\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 35\n",
      " Current loss 0.13142810761928558\n",
      "\n",
      "Epoch number 35\n",
      " Current loss 0.22156953811645508\n",
      "\n",
      "Epoch number 35\n",
      " Current loss 0.7192065715789795\n",
      "\n",
      "Epoch number 35\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 36\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 36\n",
      " Current loss 0.12351879477500916\n",
      "\n",
      "Epoch number 36\n",
      " Current loss 0.23825062811374664\n",
      "\n",
      "Epoch number 36\n",
      " Current loss 0.6432142853736877\n",
      "\n",
      "Epoch number 36\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 37\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 37\n",
      " Current loss 0.12542462348937988\n",
      "\n",
      "Epoch number 37\n",
      " Current loss 0.32133325934410095\n",
      "\n",
      "Epoch number 37\n",
      " Current loss 0.6865545511245728\n",
      "\n",
      "Epoch number 37\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 38\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 38\n",
      " Current loss 0.10838337242603302\n",
      "\n",
      "Epoch number 38\n",
      " Current loss 0.25361499190330505\n",
      "\n",
      "Epoch number 38\n",
      " Current loss 0.7266502976417542\n",
      "\n",
      "Epoch number 38\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 39\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 39\n",
      " Current loss 0.10570105910301208\n",
      "\n",
      "Epoch number 39\n",
      " Current loss 0.2712957262992859\n",
      "\n",
      "Epoch number 39\n",
      " Current loss 0.6986680626869202\n",
      "\n",
      "Epoch number 39\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 40\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 40\n",
      " Current loss 0.10086814314126968\n",
      "\n",
      "Epoch number 40\n",
      " Current loss 0.2946407198905945\n",
      "\n",
      "Epoch number 40\n",
      " Current loss 0.6938732266426086\n",
      "\n",
      "Epoch number 40\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 41\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 41\n",
      " Current loss 0.09539654850959778\n",
      "\n",
      "Epoch number 41\n",
      " Current loss 0.3188970685005188\n",
      "\n",
      "Epoch number 41\n",
      " Current loss 0.6891419291496277\n",
      "\n",
      "Epoch number 41\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 42\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 42\n",
      " Current loss 0.08765123784542084\n",
      "\n",
      "Epoch number 42\n",
      " Current loss 0.3461931049823761\n",
      "\n",
      "Epoch number 42\n",
      " Current loss 0.6792625784873962\n",
      "\n",
      "Epoch number 42\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 43\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 43\n",
      " Current loss 0.08297409117221832\n",
      "\n",
      "Epoch number 43\n",
      " Current loss 0.3718920052051544\n",
      "\n",
      "Epoch number 43\n",
      " Current loss 0.6472647190093994\n",
      "\n",
      "Epoch number 43\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 44\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 44\n",
      " Current loss 0.08151330798864365\n",
      "\n",
      "Epoch number 44\n",
      " Current loss 0.39115363359451294\n",
      "\n",
      "Epoch number 44\n",
      " Current loss 0.6425638794898987\n",
      "\n",
      "Epoch number 44\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 45\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 45\n",
      " Current loss 0.07888736575841904\n",
      "\n",
      "Epoch number 45\n",
      " Current loss 0.4163918197154999\n",
      "\n",
      "Epoch number 45\n",
      " Current loss 0.6438897252082825\n",
      "\n",
      "Epoch number 45\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 46\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 46\n",
      " Current loss 0.07692031562328339\n",
      "\n",
      "Epoch number 46\n",
      " Current loss 0.44134923815727234\n",
      "\n",
      "Epoch number 46\n",
      " Current loss 0.618694543838501\n",
      "\n",
      "Epoch number 46\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 47\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 47\n",
      " Current loss 0.07681460678577423\n",
      "\n",
      "Epoch number 47\n",
      " Current loss 0.5218964219093323\n",
      "\n",
      "Epoch number 47\n",
      " Current loss 0.5224361419677734\n",
      "\n",
      "Epoch number 47\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 48\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 48\n",
      " Current loss 0.10067947208881378\n",
      "\n",
      "Epoch number 48\n",
      " Current loss 0.4202553331851959\n",
      "\n",
      "Epoch number 48\n",
      " Current loss 0.677635133266449\n",
      "\n",
      "Epoch number 48\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 49\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 49\n",
      " Current loss 0.06861542165279388\n",
      "\n",
      "Epoch number 49\n",
      " Current loss 0.4053288698196411\n",
      "\n",
      "Epoch number 49\n",
      " Current loss 0.5691477060317993\n",
      "\n",
      "Epoch number 49\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 50\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 50\n",
      " Current loss 0.06352154910564423\n",
      "\n",
      "Epoch number 50\n",
      " Current loss 0.5372012257575989\n",
      "\n",
      "Epoch number 50\n",
      " Current loss 0.3907887041568756\n",
      "\n",
      "Epoch number 50\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 51\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 51\n",
      " Current loss 0.14246581494808197\n",
      "\n",
      "Epoch number 51\n",
      " Current loss 0.9305431246757507\n",
      "\n",
      "Epoch number 51\n",
      " Current loss 0.4102098047733307\n",
      "\n",
      "Epoch number 51\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 52\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 52\n",
      " Current loss 0.166982501745224\n",
      "\n",
      "Epoch number 52\n",
      " Current loss 0.9297171831130981\n",
      "\n",
      "Epoch number 52\n",
      " Current loss 0.5208162665367126\n",
      "\n",
      "Epoch number 52\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 53\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 53\n",
      " Current loss 0.16255423426628113\n",
      "\n",
      "Epoch number 53\n",
      " Current loss 0.9138368964195251\n",
      "\n",
      "Epoch number 53\n",
      " Current loss 0.41995134949684143\n",
      "\n",
      "Epoch number 53\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 54\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 54\n",
      " Current loss 0.11338089406490326\n",
      "\n",
      "Epoch number 54\n",
      " Current loss 0.45913323760032654\n",
      "\n",
      "Epoch number 54\n",
      " Current loss 0.37883010506629944\n",
      "\n",
      "Epoch number 54\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 55\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 55\n",
      " Current loss 0.10750474035739899\n",
      "\n",
      "Epoch number 55\n",
      " Current loss 0.8856420516967773\n",
      "\n",
      "Epoch number 55\n",
      " Current loss 0.31665146350860596\n",
      "\n",
      "Epoch number 55\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 56\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 56\n",
      " Current loss 0.24601510167121887\n",
      "\n",
      "Epoch number 56\n",
      " Current loss 1.0048261880874634\n",
      "\n",
      "Epoch number 56\n",
      " Current loss 0.3282441794872284\n",
      "\n",
      "Epoch number 56\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 57\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 57\n",
      " Current loss 0.20589910447597504\n",
      "\n",
      "Epoch number 57\n",
      " Current loss 0.8242841958999634\n",
      "\n",
      "Epoch number 57\n",
      " Current loss 0.3859490752220154\n",
      "\n",
      "Epoch number 57\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 58\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 58\n",
      " Current loss 0.11193659901618958\n",
      "\n",
      "Epoch number 58\n",
      " Current loss 1.8350327014923096\n",
      "\n",
      "Epoch number 58\n",
      " Current loss 0.28820258378982544\n",
      "\n",
      "Epoch number 58\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 59\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 59\n",
      " Current loss 1.5698877573013306\n",
      "\n",
      "Epoch number 59\n",
      " Current loss 1.1812443733215332\n",
      "\n",
      "Epoch number 59\n",
      " Current loss 0.22165317833423615\n",
      "\n",
      "Epoch number 59\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 60\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 60\n",
      " Current loss 2.926760196685791\n",
      "\n",
      "Epoch number 60\n",
      " Current loss 1.493940830230713\n",
      "\n",
      "Epoch number 60\n",
      " Current loss 0.36209583282470703\n",
      "\n",
      "Epoch number 60\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 61\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 61\n",
      " Current loss 2.065156936645508\n",
      "\n",
      "Epoch number 61\n",
      " Current loss 1.5478482246398926\n",
      "\n",
      "Epoch number 61\n",
      " Current loss 0.40390950441360474\n",
      "\n",
      "Epoch number 61\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 62\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 62\n",
      " Current loss 3.0942611694335938\n",
      "\n",
      "Epoch number 62\n",
      " Current loss 1.5159854888916016\n",
      "\n",
      "Epoch number 62\n",
      " Current loss 0.25604134798049927\n",
      "\n",
      "Epoch number 62\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 63\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 63\n",
      " Current loss 1.2457925081253052\n",
      "\n",
      "Epoch number 63\n",
      " Current loss 0.8503379821777344\n",
      "\n",
      "Epoch number 63\n",
      " Current loss 0.6378890872001648\n",
      "\n",
      "Epoch number 63\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 64\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 64\n",
      " Current loss 3.449946880340576\n",
      "\n",
      "Epoch number 64\n",
      " Current loss 1.2362669706344604\n",
      "\n",
      "Epoch number 64\n",
      " Current loss 0.3778268098831177\n",
      "\n",
      "Epoch number 64\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 65\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 65\n",
      " Current loss 1.0515738725662231\n",
      "\n",
      "Epoch number 65\n",
      " Current loss 1.1170670986175537\n",
      "\n",
      "Epoch number 65\n",
      " Current loss 0.5427182912826538\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 65\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 66\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 66\n",
      " Current loss 2.7926628589630127\n",
      "\n",
      "Epoch number 66\n",
      " Current loss 1.5497777462005615\n",
      "\n",
      "Epoch number 66\n",
      " Current loss 0.3728814125061035\n",
      "\n",
      "Epoch number 66\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 67\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 67\n",
      " Current loss 2.265895128250122\n",
      "\n",
      "Epoch number 67\n",
      " Current loss 1.3573726415634155\n",
      "\n",
      "Epoch number 67\n",
      " Current loss 0.4236902892589569\n",
      "\n",
      "Epoch number 67\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 68\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 68\n",
      " Current loss 2.7888736724853516\n",
      "\n",
      "Epoch number 68\n",
      " Current loss 1.3603814840316772\n",
      "\n",
      "Epoch number 68\n",
      " Current loss 0.41164782643318176\n",
      "\n",
      "Epoch number 68\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 69\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 69\n",
      " Current loss 2.4079394340515137\n",
      "\n",
      "Epoch number 69\n",
      " Current loss 1.2532507181167603\n",
      "\n",
      "Epoch number 69\n",
      " Current loss 0.4265110492706299\n",
      "\n",
      "Epoch number 69\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 70\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 70\n",
      " Current loss 2.682804584503174\n",
      "\n",
      "Epoch number 70\n",
      " Current loss 1.4272990226745605\n",
      "\n",
      "Epoch number 70\n",
      " Current loss 0.3824862241744995\n",
      "\n",
      "Epoch number 70\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 71\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 71\n",
      " Current loss 2.340773582458496\n",
      "\n",
      "Epoch number 71\n",
      " Current loss 1.2933087348937988\n",
      "\n",
      "Epoch number 71\n",
      " Current loss 0.41196370124816895\n",
      "\n",
      "Epoch number 71\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 72\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 72\n",
      " Current loss 2.5085105895996094\n",
      "\n",
      "Epoch number 72\n",
      " Current loss 1.3702168464660645\n",
      "\n",
      "Epoch number 72\n",
      " Current loss 0.4030079245567322\n",
      "\n",
      "Epoch number 72\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 73\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 73\n",
      " Current loss 2.531731605529785\n",
      "\n",
      "Epoch number 73\n",
      " Current loss 1.3020219802856445\n",
      "\n",
      "Epoch number 73\n",
      " Current loss 0.39365407824516296\n",
      "\n",
      "Epoch number 73\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 74\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 74\n",
      " Current loss 2.2631309032440186\n",
      "\n",
      "Epoch number 74\n",
      " Current loss 1.2898023128509521\n",
      "\n",
      "Epoch number 74\n",
      " Current loss 0.4154491126537323\n",
      "\n",
      "Epoch number 74\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 75\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 75\n",
      " Current loss 2.6754002571105957\n",
      "\n",
      "Epoch number 75\n",
      " Current loss 1.2951006889343262\n",
      "\n",
      "Epoch number 75\n",
      " Current loss 0.3820820748806\n",
      "\n",
      "Epoch number 75\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 76\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 76\n",
      " Current loss 2.1706714630126953\n",
      "\n",
      "Epoch number 76\n",
      " Current loss 1.1636570692062378\n",
      "\n",
      "Epoch number 76\n",
      " Current loss 0.40799716114997864\n",
      "\n",
      "Epoch number 76\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 77\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 77\n",
      " Current loss 2.906904935836792\n",
      "\n",
      "Epoch number 77\n",
      " Current loss 0.298013836145401\n",
      "\n",
      "Epoch number 77\n",
      " Current loss 0.39114201068878174\n",
      "\n",
      "Epoch number 77\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 78\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 78\n",
      " Current loss 1.0809273719787598\n",
      "\n",
      "Epoch number 78\n",
      " Current loss 2.1508097648620605\n",
      "\n",
      "Epoch number 78\n",
      " Current loss 8.00088882446289\n",
      "\n",
      "Epoch number 78\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 79\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 79\n",
      " Current loss 5.123604774475098\n",
      "\n",
      "Epoch number 79\n",
      " Current loss 2.423482894897461\n",
      "\n",
      "Epoch number 79\n",
      " Current loss 7.893660068511963\n",
      "\n",
      "Epoch number 79\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 80\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 80\n",
      " Current loss 60.08877944946289\n",
      "\n",
      "Epoch number 80\n",
      " Current loss 397.4397888183594\n",
      "\n",
      "Epoch number 80\n",
      " Current loss 3094.90380859375\n",
      "\n",
      "Epoch number 80\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 81\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 81\n",
      " Current loss 23.34048080444336\n",
      "\n",
      "Epoch number 81\n",
      " Current loss 5.720247268676758\n",
      "\n",
      "Epoch number 81\n",
      " Current loss 129.18853759765625\n",
      "\n",
      "Epoch number 81\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 82\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 82\n",
      " Current loss 11.321237564086914\n",
      "\n",
      "Epoch number 82\n",
      " Current loss 2.2338671684265137\n",
      "\n",
      "Epoch number 82\n",
      " Current loss 5.570530414581299\n",
      "\n",
      "Epoch number 82\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 83\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 83\n",
      " Current loss 0.5886968970298767\n",
      "\n",
      "Epoch number 83\n",
      " Current loss 1.1741138696670532\n",
      "\n",
      "Epoch number 83\n",
      " Current loss 0.005425719078630209\n",
      "\n",
      "Epoch number 83\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 84\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 84\n",
      " Current loss 0.5825864672660828\n",
      "\n",
      "Epoch number 84\n",
      " Current loss 1.550827145576477\n",
      "\n",
      "Epoch number 84\n",
      " Current loss 0.0029942623805254698\n",
      "\n",
      "Epoch number 84\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 85\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 85\n",
      " Current loss 0.5363324880599976\n",
      "\n",
      "Epoch number 85\n",
      " Current loss 1.772765040397644\n",
      "\n",
      "Epoch number 85\n",
      " Current loss 0.007257123943418264\n",
      "\n",
      "Epoch number 85\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 86\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 86\n",
      " Current loss 0.45825013518333435\n",
      "\n",
      "Epoch number 86\n",
      " Current loss 1.64118492603302\n",
      "\n",
      "Epoch number 86\n",
      " Current loss 0.023910360410809517\n",
      "\n",
      "Epoch number 86\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 87\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 87\n",
      " Current loss 0.37305840849876404\n",
      "\n",
      "Epoch number 87\n",
      " Current loss 1.6147693395614624\n",
      "\n",
      "Epoch number 87\n",
      " Current loss 0.0375978946685791\n",
      "\n",
      "Epoch number 87\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 88\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 88\n",
      " Current loss 0.32859471440315247\n",
      "\n",
      "Epoch number 88\n",
      " Current loss 1.593335747718811\n",
      "\n",
      "Epoch number 88\n",
      " Current loss 0.04867001995444298\n",
      "\n",
      "Epoch number 88\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 89\n",
      " Current loss 3.9999942779541016\n",
      "\n",
      "Epoch number 89\n",
      " Current loss 0.2970309257507324\n",
      "\n",
      "Epoch number 89\n",
      " Current loss 1.5958772897720337\n",
      "\n",
      "Epoch number 89\n",
      " Current loss 0.05449717491865158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = SiameseNetwork()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "for epoch in range(0,100):\n",
    "    net.train()\n",
    "    \n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = net(data.img1, data.img2)\n",
    "        loss_contrastive = criterion(output1, output2, data.y)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i %10 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f140c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = []\n",
    "pred = []\n",
    "for data in train_loader:\n",
    "    output1,output2 = net(data.img1, data.img2)\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2).item()\n",
    "    if euclidean_distance < 1:\n",
    "        pred.append(0)\n",
    "    else:\n",
    "        pred.append(1)\n",
    "    \n",
    "    gt.append(data.y.item())\n",
    "        \n",
    "AC = accuracy_score(gt, pred)\n",
    "f1_grid = precision_recall_fscore_support(gt, pred, average='macro')\n",
    "prec = f1_grid[0]\n",
    "rec = f1_grid[1]\n",
    "f1 = f1_grid[2]\n",
    "\n",
    "print('Accuracy: ', AC)\n",
    "print('precision: ', prec)\n",
    "print('recall: ', rec)\n",
    "print('fscore: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testload = validation_sampler(\n",
    "    zip(X_test, y_test),\n",
    "    [0,0,0,1,1,1,0,0,1,1,0,0,0,0,1],\n",
    "    #[random.randint(0,1) for _ in range(20)]\n",
    "    )\n",
    "test_loader = DataLoader(testload, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f002b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = [x for x, y in validationload if y == 0][0]\n",
    "class1 = [x for x, y in validationload if y == 1][0]\n",
    "\n",
    "gt = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data in test_loader:\n",
    "        output1, output2 = net(class0, data.img)\n",
    "        class0_euc_score = F.pairwise_distance(output1, output2).item()\n",
    "        output1, output2 = net(class1, data.img)\n",
    "        class1_euc_score = F.pairwise_distance(output1, output2).item()\n",
    "\n",
    "        print(class0_euc_score, class1_euc_score)\n",
    "        if class0_euc_score < class1_euc_score:\n",
    "            pred.append(0)\n",
    "        elif class0_euc_score > class1_euc_score:\n",
    "            pred.append(1)\n",
    "\n",
    "        gt.append(data.y[0])\n",
    "        \n",
    "        \n",
    "AC = accuracy_score(gt, pred)\n",
    "auc = roc_auc_score(gt, pred)\n",
    "f1_grid = precision_recall_fscore_support(gt, pred, average='macro')\n",
    "prec = f1_grid[0]\n",
    "rec = f1_grid[1]\n",
    "f1 = f1_grid[2]\n",
    "\n",
    "print('Accuracy: ', AC)\n",
    "print('AUC', auc)\n",
    "print('precision: ', prec)\n",
    "print('recall: ', rec)\n",
    "print('fscore: ', f1)\n",
    "print(\"Pred: \", pred)\n",
    "print(\"Pred: \", gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48c49b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
